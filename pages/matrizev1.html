<h1>Matriz de Análisis Ético Laboral: Dilema IA</h1>

<table>
  <thead>
    <tr>
      <th>Elemento</th>
      <th>Preguntas Orientadoras</th>
      <th>Respuesta</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1. Personajes involucrados</td>
      <td>¿Quiénes son los protagonistas y actores clave del caso?</td>
      <td>
        <ul>
          <li>Desarrolladores y científicos de datos que diseñan y entrenan algoritmos.</li>
          <li>Empresas tecnológicas y de seguridad que implementan sistemas de IA.</li>
          <li>Gobiernos y reguladores que establecen normas para su uso.</li>
          <li>Ciudadanos y usuarios, afectados por decisiones automatizadas y vigilancia.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>2. Contexto del caso</td>
      <td>¿En qué situación laboral ocurre y/o cuál es el contexto del dilema?</td>
      <td>
        <ul>
          <li>La IA se utiliza en seguridad, salud, transporte y educación.</li>
          <li>Se discute en Europa un marco regulador para evitar abusos en aplicaciones de alto riesgo.</li>
          <li>Empresas implementan comités de ética y mecanismos de consentimiento en el tratamiento de datos.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>3. Problemática ética</td>
      <td>¿Cuál es la problemática ética que está al centro del dilema?</td>
      <td>
        <ul>
          <li>El uso de algoritmos puede afectar derechos fundamentales (privacidad, dignidad, no discriminación).</li>
          <li>Decisiones automatizadas que pueden ser sesgadas, opacas o desproporcionadas.</li>
          <li>El conflicto entre innovación tecnológica y protección de derechos.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>4. Normas o principios</td>
      <td>¿Qué normas legales o principios éticos se ven implicados?</td>
      <td>
        <ul>
          <li>Reglamento Europeo sobre IA en discusión, que prohíbe usos de alto riesgo sin garantías.</li>
          <li>Principios de transparencia, necesidad y proporcionalidad en la aplicación tecnológica.</li>
          <li>Respeto a la privacidad y al consentimiento en el uso de datos personales.</li>
          <li>Principio de no discriminación y equidad algorítmica.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>5. Opciones de acción</td>
      <td>¿Qué consecuencias tiene seguir con la problemática en el tiempo?</td>
      <td>
        <ul>
          <li>Opción 1: Implementar IA sin controles éticos (riesgo de sanciones, pérdida de confianza y daño social).</li>
          <li>Opción 2: Adoptar protocolos de ética, comités internos y cumplir normativa (costos iniciales, pero confianza y sostenibilidad a largo plazo).</li>
          <li>Opción 3: Detener aplicaciones sensibles hasta contar con garantías técnicas y legales.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>6. Juicio ético</td>
      <td>¿Qué opción parece la mejor y más razonable? ¿Qué principios la fundamentan?</td>
      <td>
        <ul>
          <li>La opción más razonable es la Opción 2: aplicar protocolos de ética y cumplir regulaciones.</li>
          <li>Se fundamenta en la responsabilidad profesional, la transparencia y la defensa de los derechos humanos.</li>
          <li>Permite equilibrar innovación con confianza pública y legitimidad social.</li>
          <li>Esta auto-exigencia ética debe ir más allá de lo legal, dado que ley puede avanzar más lenta que los cambios tecnológicos.</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>7. Lecciones del caso</td>
      <td>¿Qué se puede aprender?</td>
      <td>
        <ul>
          <li>La ética debe ser parte integral del desarrollo tecnológico, no un añadido posterior.</li>
          <li>Los profesionales deben anticipar y prevenir riesgos sociales y legales antes del despliegue.</li>
          <li>La confianza en la IA depende de transparencia, equidad y respeto por la privacidad.</li>
          <li>Los profesionales detrás de las IA se les exigirá un nivel de compromiso ético comparable al de los médicos con su "juramento hipocrático".</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
